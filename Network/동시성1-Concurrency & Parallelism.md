# Concurrency와 Parallelism

## Parallelism(병렬성)
> &nbsp;Parallelism은 어떠한 작업이 하위작업으로 나뉘어 물리적으로 동시에처리가 되는 일을 의미한다.
> 예를 들면, 행렬 곱셈이 대표적이다.

![image](https://user-images.githubusercontent.com/74396651/199500462-9519e363-709e-47ce-acc8-0413dd9527b8.png)

<br>
> &nbsp;위와 같은 행렬 연산이 있을 때, 연산 결과의 각 요소를 순차적으로 계산한다면 많은 연산 시간이 소요될 것이다. N * M인 행렬과 M * L인 행렬을 곱하면 O(N * M * L) 의 시간이 소요될 것이다. 하지만 충분한 양의 연산 장치가 있다면, 각 요소의 값들을 동시에 계산해 O(M)의 시간 밖에 소요되지 않을 수 있을것이다. 이를 일반화 할 수 있는 대표적인 사례는 Monoid이다. Monoid는 다음 세가지 성질을 만족하는 함수 및 데이터 타입이다.

### 1. 결합법칙이 성립한다.
- Monoid 함수 f가 있을 때, 임의 값 a, b, c에 대해 다음과 같은 교환법칙이 성립해야 한다.
```java
f(a, f(b, c) = f(f(a, b), c)
```

<br>

### 2. 항등원이 존재한다.
- 임의의 Monoid 함수 f, 값 x에 대해 다음과 같은 고정 값 i가 존재해야 한다.
```java
f(i, x) = f(x, i) = x
```

<br>

### 3. 닫혀있어야 한다.
- 임의의 값 a, b에 대해서 f(a, b) 의 결과인 c 는 항상 f 의 인자로 사용될 수 있어야한다..
- 이러한 규칙들이 복잡해 보이지만 사실 에시를 들면 매우 간단한 사례라는것을 알 수 있다.
- 대표적인 Monoid의 예시는 덧셈과 곱셈이다.
   - 덧셈을 예로 들면, 임의의 수 a, b, c 에 대해서 항상 a + (b + c) = (a + b) + c 를 만족하고 a + 0 = 0 + a = a를 만족한다.
   - 마찬가지로 곱셉의 경우에도 임의의 수 a, b, c 에 대해서 항상 a x (b x c) = (a x b) x c 를 만족하고 a x 1 = 1 x a = a 를 만족한다.
- 이러한 경우 Monoid는 매우 쉽게 Parallelism을 이용한 최적화를 이룰 수 있는데, 다음과 같은 변환을 통해 일어난다.
```java
// 10000일 경우

f(1, f(2, f(3, ... f(9999, 10000)...))) // -> N개의 중첩 연산을 순차적으로 계산할 경우 O(N) 연산시간이 소요될 것이다.

f(f(f(1, 2), f(3, 4)), f(5, 6), ... f(9999, 10000)...)) // 1. 결합법칙으로 바꿀 수 있다.

// 만약 f가 덧셈일 경우 다음과 같이 표현할 수 있다.
(1 + 2) + (3 + 4) + ... + (9997 + 9998) + (9999 + 10000)
= (3 + 7) + ... + (19995 + 19999)
= 12502500 + 37502500
= 50005000

--> 이렇게 할 경우 N개 이상의 연산장치가 존재할 때 연산에 필요한 시간은 O(log2(N))이 된다.

```

![image](https://user-images.githubusercontent.com/74396651/199507048-c22fe086-f7a7-4ca3-b015-e215d2a4e136.png)

- 실제로 1부터 8까지 더하는 연산은 이렇게 계산될 수 있다.

#### 이렇게 볼  수 있듯이 Monoid는 Parallelism을 통해 효율적으로 계산할 수 있는 대표적인 연산이 된다.

<hr>

## Concurrency(병행성)
> &nbsp;Parallelism이 하나의 문제를 풀기 위해 여러 작업을 동시에 수행하는 것이라면, Concurreny는 여러 작업을 동시에 수행하는 것 그 자체 혹은 동시에 수행되는 것처럼 보이는 것으 말한다.

#### 웹 서버를 예로 들어보겠다.
- 다음과 같이 여러 요청을 동시에 처리하는 것을 예로 들 수 있다.

![image](https://user-images.githubusercontent.com/74396651/199508765-6afda1f2-a5b0-4e59-a2fd-56a8f10a643a.png)

- 위 상황에서 CPU는 2대이지만, CPU들은 요청을 한번에 하나씩 처리하지 않고 여러개의 요청을 Time-sharing 방식으로 처리하게 된다. 
- 이처럼 실제로 동시에 수행되는것과 관계 없이, 각 작업 전체를 순차적으로 처리하는 것이 아닌 여러 방법에 따라 동시에 수행하는것을 Concurrency라고 이야기한다.

<hr>

- time-sharing(시분할 시스템)
    - 시분할 운영 체제는 CPU 스케줄링과 다중 프로그래밍을 이용해서 각 사용자들에게 컴퓨터 자원을 시간적으로 분할하여 사용할 수 있게 해 준다. 
    - 시분할 운영 체제는 많은 사용자들이 컴퓨터를 공유하도록 한다. 
    - 시스템은 한 사용자에서 다음 사용자로 빠르게 전환함으로써 각 사용자에게 자신만이 컴퓨터를 사용하고 있는 것과 같은 착각을 주지만, 실제로는 여러 사용자가 하나의 컴퓨터를 공유하d여 사용하고 있는 것이다.
- 다중 프로그래밍
    - CPU 작업과 입출력 작업을 병행하는 것이다. 
    - 다중 프로그래밍 운영체제에서 여러 개의 작업들이 수행할 준비를 갖추고 있다면 이 작업들 중에 하나를 선택하기 위해서 CPU 스케줄링이 필요하다.
- 스케쥴링
    - 다중 프로그래밍을 가능하게 하는 운영 체제의 동작 기겁. 운영 체제는 프로세스들에게 CPU 등의 자원 배정을 적절히 함으로써 시스템의 성능을 개선할 수 있다.
- 입출력 
    -  데이터 등의 모든 항목의 입추력으로, 입력과 출력을 아우르는 개념이다. Input/Output을 따 I/O라고 줄여 말하기도 한다. 
    -  정보 처리의 개념에 근거해서 입출력은 데이터나 정보 등을 가공하는 과정(프로세스)의 전처리와 후처리라고 생각할 수 잇다.
    -  컴퓨터끼리 정보를 제공하는 통신(컴퓨터 네트워크)도 입출력에 해당한다.

